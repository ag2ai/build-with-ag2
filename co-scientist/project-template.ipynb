{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project template for AG2 projects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use this project template as a starting point for your custom project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from autogen import AssistantAgent, UserProxyAgent, config_list_from_json\n",
        "\n",
        "# Load LLM inference endpoints from an env variable or a file\n",
        "# See https://docs.ag2.ai/docs/FAQ#set-your-api-endpoints\n",
        "# and OAI_CONFIG_LIST_sample\n",
        "\n",
        "config_list = config_list_from_json(env_or_file=\"OAI_CONFIG_LIST\")\n",
        "# You can also set config_list directly as a list, for example, config_list = [{'model': 'gpt-4o', 'api_key': '<your OpenAI API key here>'},]\n",
        "assistant = AssistantAgent(\"assistant\", llm_config={\"config_list\": config_list})\n",
        "user_proxy = UserProxyAgent(\n",
        "    \"user_proxy\", code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False}\n",
        ")  # IMPORTANT: set to True to run code in docker, recommended\n",
        "user_proxy.initiate_chat(\n",
        "    assistant, message=\"Plot a chart of NVDA and TESLA stock price change YTD.\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "autogenstudio",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
